[{"authors":["t.mcandrew"],"categories":null,"content":"","date":1573603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573603200,"objectID":"7b610e87ab09567bae22bf24cc46eb1a","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class24/","publishdate":"2019-11-13T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class24/","section":"publication","summary":"","tags":null,"title":"(Class 24) Ensembles: Stacking","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":"","date":1573516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573516800,"objectID":"d0198e5e5007aaebd69fc072b8bc98f9","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class23/","publishdate":"2019-11-12T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class23/","section":"publication","summary":"","tags":null,"title":"(Class 23) Ensembles: Bagging","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":"","date":1572825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572825600,"objectID":"b711256215da4186de848acf3c10f20d","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class22/","publishdate":"2019-11-04T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class22/","section":"publication","summary":"","tags":null,"title":"(Class 22) Tree-based regression","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"7a7461823a096f94464f7547bf39daa1","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class21/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class21/","section":"publication","summary":"","tags":null,"title":"(Class 21) Ridge Regression and LASSO","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":"","date":1572480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572480000,"objectID":"e9da895f296a924e912562d5e25f63a5","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class20/","publishdate":"2019-10-31T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class20/","section":"publication","summary":"","tags":null,"title":"(Class 20) Collaborative filtering and KNN","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":"","date":1572220800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572220800,"objectID":"21e3fef60419515cfd3c3586e4bd38a1","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class19/","publishdate":"2019-10-28T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class19/","section":"publication","summary":"","tags":null,"title":"(Class 19) Logistic Regression for a Binomial R.V.","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class Reading  ISLR  4.3.1-4.3.5   ","date":1572134400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572134400,"objectID":"05202ff74edfcc70672a21b83c4b79bb","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class18/","publishdate":"2019-10-27T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class18/","section":"publication","summary":" During class Reading  ISLR  4.3.1-4.3.5   ","tags":null,"title":"(Class 18) KNN for Classification","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class Reading  ISLR  4.3.1-4.3.5   ","date":1571788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571788800,"objectID":"1c629e2a1e40d9ab138d7f9f37a58c40","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class17/","publishdate":"2019-10-23T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class17/","section":"publication","summary":" During class Reading  ISLR  4.3.1-4.3.5   ","tags":null,"title":"(Class 17) Logistic Regression Lab","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Recap Logistic regression and MLE Discuss Measures of Accuracy for classification Preview Lab  Reading  ISLR  4.3.1-4.3.5   ","date":1571616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571616000,"objectID":"ad06b58a019e14ae7ad671e4cc6f3bf9","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class16/","publishdate":"2019-10-21T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class16/","section":"publication","summary":"We will recap logistic regression, MLE, and discuss metrics for evaluating classification models","tags":null,"title":"(Class 16) Bernoulli, Binomial, and MLE ","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Bernoulli distribution Binomial distribution MLE Maximum likelihood for linear regression Maximum likelihood for logistic regression  Reading  ISLR  4.3.1-4.3.5   ","date":1571270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571270400,"objectID":"e17250a0774465b7dbc18347df589b4a","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class15/","publishdate":"2019-10-17T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class15/","section":"publication","summary":"We will discuss Bernoulli and Binomial distributed random variables, and using maximum likelihood to compute optimal coefficients for logistic regression","tags":null,"title":"(Class 15) Bernoulli, Binomial, and MLE ","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Derive a one unit change in a logistic regression model Understand how to interpret coefficients Compute Accuracy, False positive, True positive, False negative, and True negative Compute Positive and negative predictive error.  Reading  ISLR  4.3.1-4.3.5   ","date":1571097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571097600,"objectID":"495334474980195561ae1dd71090fe50","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class14/","publishdate":"2019-10-15T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class14/","section":"publication","summary":"We will discuss how to interpret coefficients for a logistic regression model and measures of accuracy","tags":null,"title":"(Class 14) Interpreting coefficients and measures of accuracy","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Explore the classification problem Try past methods for regression Explore the logistic function  Reading  ISLR  4.3.1 4.3.2 4.3.3   ","date":1570838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570838400,"objectID":"020bdc466207d872e2e2deec109cbb74","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class13/","publishdate":"2019-10-12T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class13/","section":"publication","summary":"We will discuss the disadvantages of linear regression and begin logistic regression","tags":null,"title":"(Class 13) Classification","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Introduce LAB Work together on LAB  ","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569974400,"objectID":"94a5c65f91a113edc312cedeef714b83","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class11/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class11/","section":"publication","summary":"We will discuss the impact of transforming the dependent variable in regression.","tags":null,"title":"(Class 11) Transform lab","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  KNN methods  ","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569974400,"objectID":"40a363f594268ed59dc0ae9470681bb0","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class12/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class12/","section":"publication","summary":"We will discuss the K nearest neighbor approach to regression.","tags":null,"title":"(Class 12) KNN regression","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  LINE assumptions Transforming X CDF and PDF QQ-plot N assumption and E assumption  Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1569456000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569456000,"objectID":"ba9aad20893aa9102b6dc6264bcaa11c","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class10/","publishdate":"2019-09-26T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class10/","section":"publication","summary":"We will discuss the impact of transforming the dependent variable in regression.","tags":null,"title":"(Class 10) Transformations","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Bias-Variance tradeoff  Prof Ray\u0026rsquo;s BV tradeoff  Lab  For Loops extra Crossval   Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1569110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569110400,"objectID":"93d49d4b770a79bbfeac3fcfaf699129","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class9/","publishdate":"2019-09-22T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class9/","section":"publication","summary":"We will discuss the bias-variance tradeoff.","tags":null,"title":"(Class 09) Bias-variance tradeoff","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  LAB  R cheatsheets  Prof Ray\u0026rsquo;s R cheatsheet R cheatsheet R cheatsheet 2 R cheatsheet 3 R cheatsheet 4  Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1568851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568851200,"objectID":"90342c56d4a9870a89bc7c034f2f1e78","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class8/","publishdate":"2019-09-19T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class8/","section":"publication","summary":"We will discuss the importance of having separate training and testing datasets and the bias-variance tradeoff.","tags":null,"title":"(Class 08) Cross-validation Lab","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Orthogonality Projections Orthogonal projection as a minimizer Hat matrix and regression as an orthogonal projection  After class  Checkout this cool example of orth. proj and regression (Courtesy of Prof.Ray) link  Reading  Notes. Our ISLR book doesn\u0026rsquo;t include this material.  ","date":1568764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568764800,"objectID":"e750f63a7aa2da7550097fed0b08de39","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class7/","publishdate":"2019-09-18T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class7/","section":"publication","summary":"We will explore how orthogonality relates to optimization","tags":null,"title":"(Class 07) Orthogonal projections as a method of optimization.","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Training, testing, and validation (3.3 of ISLR) MSE Bias-variance tradeoff  Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1568592000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568592000,"objectID":"66d378ac691b1b0a5bc3ba6ec3d0f8bc","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class6/","publishdate":"2019-09-16T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class6/","section":"publication","summary":"We will discuss the importance of having separate training and testing datasets and the bias-variance tradeoff.","tags":null,"title":"(Class 06) Testing, training, and validation data, and the Bias-variance tradeoff.","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Minimizing SSE for MLR Start and finish hat matrix discussion  Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1568246400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568246400,"objectID":"e49d982a06f2bf63ce2657fa3ea962d6","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class5/","publishdate":"2019-09-12T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class5/","section":"publication","summary":"We will discuss optimzing regression parameters using SSE and the Hat Matrix","tags":null,"title":"(Class 05) SSE optimization.","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Finish discussion on optimizing SSE Discuss Cov/Var Discuss (X\u0026rsquo;X)^-1(X\u0026rsquo;y) Lab  ","date":1565481600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565481600,"objectID":"1fa2bb574ff6e13631eb9c41beeab397","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class4/","publishdate":"2019-08-11T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class4/","section":"publication","summary":"Lab on fitting simple, multiple, and polynomial models to Boston housing data","tags":null,"title":"(Class 04) Lab on fitting simple, multiple, and polynomial models to Boston housing data.","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Multiple Regression  Example of translating data into regression  Polynomial Regression (3.3 of ISLR) Optimizing via SSE  Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1565395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565395200,"objectID":"f900ed04660fe20e627dadc401ebf82f","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class3/","publishdate":"2019-08-10T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class3/","section":"publication","summary":"We will explore polynomial regression for modeling non-linear relationships and optimizing parameters given data","tags":null,"title":"(Class 03) Polynomial regression, optimizing parameters via SSE","type":"publication"},{"authors":null,"categories":null,"content":"","date":1565222400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565222400,"objectID":"e59b85338820a9c7c7eacea33f0a6b8d","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/teaching/2019_mhc_stat340/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/teaching/2019_mhc_stat340/","section":"teaching","summary":"","tags":null,"title":"Stat340 Applied Regression","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1565222400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565222400,"objectID":"98546ce85a5506ff266ec1dcc257c141","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/teaching/2019_mhc_stat340/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/teaching/2019_mhc_stat340/","section":"teaching","summary":"","tags":null,"title":"Stat340 Applied Regression (MHC)","type":"teaching"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Warmup activity (in groups) Linear regression commands in R Setup GitHub  Video overview Detailed instructions Please enter your name and github username in this form    Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   ","date":1564963200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564963200,"objectID":"d38b57677fdec949bcfbec7a205a667c","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class2/","publishdate":"2019-08-05T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class2/","section":"publication","summary":"We will explore model and probabilistic forms of simple linear regression.","tags":null,"title":"(Class 02) Polynomial regression, testing and training","type":"publication"},{"authors":["t.mcandrew"],"categories":null,"content":" During class  Overview of course Matrix notation for multiple regression  Ch. 1 of ISLR and Lin Reg Wiki    After Class Todos  Signup for our piazza page  Piazza will be a valuable tool for asking questions throughout the semester.   Reading  ISLR  Chapter 1 2.1, 2.2.1, 2.2.2 3.1, 3.2, and 3.3   This material should be mostly familiar, but we will discuss the above during the first two weeks or so of class.\n","date":1564876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564876800,"objectID":"95582c2e2c97a08288b0db68335f8e80","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/publication/class1/","publishdate":"2019-08-04T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/publication/class1/","section":"publication","summary":"We will take time to setup technical requirements for class (R and Github), and introduce matrix notation for simple linear regression","tags":null,"title":"(Class 01) Technical setup and Matrix notation related to regression","type":"publication"},{"authors":["t mcandrew"],"categories":[],"content":" Diff. Eq and bifurcations A differential equation relates a function to it\u0026rsquo;s derivatives. For more general systems involving many different functions, a system of differential equations relates the set of functions to their derivatives.\nFor example, $$ \\begin{equation} \\frac{dy}{dt} = y\\sin(t) \\end{equation} $$ and $$ \\begin{equation} A \\frac{d^{2}y}{dt^{2}} + B\\frac{dy}{dt} + C = 0, \\end{equation} $$ are differential equations. The first describes $y$ using the first derivative only, the second equation involving $y$\u0026rsquo;s first and second derivatives.\nThe goal of any differential equation (difeq) is finding a solution, finding a function $f$ that satisfies all the constraints imposed by the difeq. Looking at our first example diffeq., a solution would be a function $y(t)$ such that the first derivative equals $y(t) \\times \\sin(t)$. The function $y_{1}(t) = e^{t^{2}}$ would not be a solution,\n$$ \\begin{equation} \\frac{dy_{1}}{dt} = 2t e^{t^{2}} = 2t y_1 \\neq y_1 \\sin(t). \\end{equation} $$\nbut $ y(t) = k e^{-\\cos(t)} $, $k$ a constant, is a solution (check). Given a starting point $(t_0,y_0)$ the solution (red) oscillates, at greater magnitude for larger positive and negative $y$ values (Fig).\nAs another example, consider the diff eq. $$ \\frac{dx}{dt} = 5-x^2 $$\nLacking any external influencers, a solution like the one above can completely describe the system. When a system can be influenced by external forces, more is needed to describe the system.\nConsider the diffeq. $$ \\frac{dx}{dt} = f(x|r) = r-x^2 $$\nCritical Slowing Down Influenza like illness ","date":1560189989,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560189989,"objectID":"a5056b69487e1e09c1ed5f49b32d126f","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/post/critical-slowing-down-influenza/","publishdate":"2019-06-10T14:06:29-04:00","relpermalink":"/classes/2019_stat340_MHC/public/post/critical-slowing-down-influenza/","section":"post","summary":"I'll give a brief overview of Dif. Eq and critical slowing down applied to predicting peak Influenza incidence.","tags":[],"title":"Critical Slowing Down and US Influenza incidence","type":"post"},{"authors":null,"categories":null,"content":"Seasonal Influenza infects an average 30 million people in the United States every year, overburdening hospitals during weeks of peak incidence.Named by the CDC as an important tool to fight the damaging effects of these epidemics, accurate forecasts of influenza and influenza like illness (ILI) forewarn public health officials about when, and where, seasonal influenza outbreaks will hit hardest.\nEnsemble forecasts have shown positive results in forecasting 1 to 4 week ahead ILI percentages better than any single model in an ensemble.But current ensemble forecasts are static within a season, training on past ILI data before the season begins and generating optimal weights for each model kept constant throughout the season.We propose a novel adaptive ensemble forecast capable of changing model weights week-by-week throughout the flu season, only needing current flu season data to make predictions, and able to moderate ensemble weights with a prior chosen through cross-validation.At the start of the season, without any data, models are weighted equally, and after observing how the ensemble\u0026rsquo;s models perform on week ahead forecasts, a variational inference algorithm updates model weights and forecasts the next 4 weeks of ILI percentages.\nOur adaptive ensemble performs as well as the static ensemble in the US national and regional level (mean % dif.in log-score between adaptive and static ensemble = 1.1;upper 97.5CI =1.4) and better for more sparse seasons (e.g. Season 2011\u0026frasl;2012;mean = -2.9;95CI = [-3.7, -2.1];p\u0026lt;0.01).The choice of prior (equal across models) also affects adaptive ensemble performance, finding the best logscore with a prior weight equal to 8% of the training data.\nIn settings without substantial past data (i.e. emerging pandemics) or when new models do not have a long track-record of performance, an adaptive ensemble approach will be the only option for performance-based weighting of models, enhancing the public health impact of ensemble forecasts.\n","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559260800,"objectID":"d018217d394a23c05e1d2c8bd70c3f3b","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2019sdss/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2019sdss/","section":"talk","summary":"Seasonal Influenza infects an average 30 million people in the United States every year, overburdening hospitals during weeks of peak incidence.Named by the CDC as an important tool to fight the damaging effects of these epidemics, accurate forecasts of influenza and influenza like illness (ILI) forewarn public health officials about when, and where, seasonal influenza outbreaks will hit hardest.\nEnsemble forecasts have shown positive results in forecasting 1 to 4 week ahead ILI percentages better than any single model in an ensemble.","tags":null,"title":"Adaptively stacked ensembles for influenza forecasting with incomplete data","type":"talk"},{"authors":null,"categories":null,"content":"Influenza prediction can better prepare public health officials for seasonal outbreaks. We propose an adaptive multi-model ensemble forecast method that changes model weights week-by-week throughout the flu season. Without historical training data or when models do not have a track-record, an adaptive model can enhance the public health impact of ensemble forecasts.\n","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"95a1fa09690f060633d9b496a416a4c3","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2019adaptivemidas/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2019adaptivemidas/","section":"talk","summary":"Influenza prediction can better prepare public health officials for seasonal outbreaks. We propose an adaptive multi-model ensemble forecast method that changes model weights week-by-week throughout the flu season. Without historical training data or when models do not have a track-record, an adaptive model can enhance the public health impact of ensemble forecasts.","tags":null,"title":"Adaptively stacked ensembles for influenza forecasting with incomplete data","type":"talk"},{"authors":null,"categories":null,"content":"Seasonal Influenza infects an average 30 million people in the United States every year, overburdening hospitals during weeks of peak incidence. Named by the CDC as an important tool to fight the damaging effects of these epidemics, accurate forecasts of influenza and influenza like illness (ILI) forewarn public health officials about when, and where, seasonal influenza outbreaks will hit hardest.\nEnsemble forecasts have shown positive results in forecasting 1 to 4 week ahead ILI percentages better than any single model in an ensemble. But current ensemble forecasts are static within a season, training on past ILI data before the season begins and generating optimal weights for each model kept constant throughout the season. We propose a novel adaptive ensemble forecast capable of changing model weights week-by-week throughout the flu season, only needing current flu season data to make predictions, and by adding a prior, able to moderate abrupt changes in ensemble weights that may be caused by mid-seasons revisions to past ILI data.\nDuring the course of the flu season hospitals and agencies experience reporting delays, changing ILI percentages from past weeks. ILI percentages only considered final when the flu season ends, adding a prior distribution over ensemble weights allows us to account for incomplete, weekly-changing historical data. At the start of the season and without any data, models are weighted equally. After observing how the ensemble\\\u0026rsquo;s models perform on week ahead forecasts, a variational inference algorithm updates model weights and forecasts the next 4 weeks of ILI percentages.\nObtaining an optimal prior weighting equal to 8% of the training data to account for incomplete ILI percentages, our adaptive ensemble shows comparable performance to the static ensemble season to season (mean % dif. log-score = 0.03; 95CI = [-0.01,0.08]).\nIn settings without substantial historical training data (i.e. emerging pandemics) or when new forecasting models do not have a long track-record of performance, an adaptive ensemble approach is a valuable option for performance-based weighting of models, enhancing the public health impact of ensemble forecasts.\n","date":1557964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557964800,"objectID":"8df0579eacd9d8d2609b92163c42ee4f","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2019adaptive/","publishdate":"2019-05-16T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2019adaptive/","section":"talk","summary":"Seasonal Influenza infects an average 30 million people in the United States every year, overburdening hospitals during weeks of peak incidence. Named by the CDC as an important tool to fight the damaging effects of these epidemics, accurate forecasts of influenza and influenza like illness (ILI) forewarn public health officials about when, and where, seasonal influenza outbreaks will hit hardest.\nEnsemble forecasts have shown positive results in forecasting 1 to 4 week ahead ILI percentages better than any single model in an ensemble.","tags":null,"title":"Adaptively stacked ensembles for influenza forecasting with incomplete data","type":"talk"},{"authors":null,"categories":null,"content":"Moderators: Peter Juni, Robert W. Yeh\nDiscussants: John A. Bittl, Eugene H. Blackstone, Schuyler Jones, Thomas C. McAndrew, Roxana Mehran, Stuart J. Pocock, Matthew T. Roe\n3:50 PM How to Make Trials Larger Simpler and Less Expensive Lecturers: Matthew T. Roe\n4:00 PM Most Frequent Errors I See in the Analysis and Interpretation of Trials Lecturers: Peter Juni\n4:10_PM Non Inferiority Trials Gone Wrong: Examples From the Recent Literature Lecturers: David J. Cohen\n4:20_PM Stent Trials in High Bleeding Risk Patients: What is the Level of Evidence We Need Lecturers: Roxana Mehran 4:30_PM Roundtable Discussion with Audience\n","date":1536364800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536364800,"objectID":"319845fb632b52b8f51a5d39ddb58bd5","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2018tct/","publishdate":"2018-09-08T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2018tct/","section":"talk","summary":"Moderators: Peter Juni, Robert W. Yeh\nDiscussants: John A. Bittl, Eugene H. Blackstone, Schuyler Jones, Thomas C. McAndrew, Roxana Mehran, Stuart J. Pocock, Matthew T. Roe\n3:50 PM How to Make Trials Larger Simpler and Less Expensive Lecturers: Matthew T. Roe\n4:00 PM Most Frequent Errors I See in the Analysis and Interpretation of Trials Lecturers: Peter Juni\n4:10_PM Non Inferiority Trials Gone Wrong: Examples From the Recent Literature Lecturers: David J.","tags":null,"title":"Clinical trial design in context (discussant)","type":"talk"},{"authors":null,"categories":null,"content":"Background: Left ventricular ejection fraction (LVEF) is the most commonly used clinical measure of systolic function and is a powerful predictor of outcomes. Current guidelines recommend using the biplane method of discs (MOD) (modified Simpson’s rule) to measure LVEF however the accuracy of this measurement is dependent on endocardial border detection and orthogonal, on-axis biplane imaging, and studies report both inter and intraobserver variability.\nObjectives: In this analysis, we sought to reduce measurement error by fusing the cardiologist\u0026rsquo;s visual approximation of LVEF with the biplane MOD. Furthermore, we hypothesized that this new assimilated LVEF will better correlate with clinical outcomes.\nMethods: We studied intermediate surgical risk patients with severe, symptomatic aortic stenosis from the PARTNER-IIA Trial treated with either surgical or transcatheter bioprosthetic aortic valves, who had core-lab assessments of both a visual estimate and a biplane MOD measurement of LVEF.\nResults: Assimilating the core lab cardiologist’s visual estimate with the biplane MOD estimate, reduces variability by 28.7% on average compared to the biplane MOD estimate alone. After accounting for LVEF measurement error, the assimilated LVEF shrank confidence intervals for the association between LVEF\u0026lt; 35% and the composite of 1 year cardiovascular death compared to biplane MOD (pvalue \u0026lt; 0.01)\nConclusions: Combining an experienced echocardiographer’s visual estimates and biplane MOD measurements, can reduce reproducibility errors in LVEF measurement and improve the association between LVEF and cardiovascular mortality at 1 year in a large, population-based study.\nKeywords: Left Ventricular ejection fraction, measurement error, PARTNER, TAVR\n","date":1529625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529625600,"objectID":"58edf39eee9f7e0badc0ecb1b061db4d","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2018assimilated/","publishdate":"2018-06-22T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2018assimilated/","section":"talk","summary":"Background: Left ventricular ejection fraction (LVEF) is the most commonly used clinical measure of systolic function and is a powerful predictor of outcomes. Current guidelines recommend using the biplane method of discs (MOD) (modified Simpson’s rule) to measure LVEF however the accuracy of this measurement is dependent on endocardial border detection and orthogonal, on-axis biplane imaging, and studies report both inter and intraobserver variability.\nObjectives: In this analysis, we sought to reduce measurement error by fusing the cardiologist\u0026rsquo;s visual approximation of LVEF with the biplane MOD.","tags":null,"title":"Assimilated LVEF: Combining human intuition with machine measurements for sharper estimates of left ventricular ejection fraction","type":"talk"},{"authors":null,"categories":null,"content":"Spotlight on Interpreting Evidence: The P-value and Beyond 2:45 PM - 3:30 PM Moderators: Eugene H. Blackstone, Stuart J. Pocock\nDiscussants: Donald Cutlip, A. Michael Lincoff, Thomas C. McAndrew, Jan G. P. Tijssen, Marco Valgimigli, Roseann M White\n2:45 PM Proper and Improper Interpretations of the P-value Eugene H. Blackstone\n2:55 PM Beyond Time-to-First Event: Counting Multiple Events, Hierarchical Measures, and Weighted Composites Jan G. P. Tijssen\n3:05 PM Alternatives to Traditional P-value Testing: Bayesian Designs Roseann M White\n3:15 PM Roundtable Discussion With Audience Q\u0026amp;A\n","date":1504828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504828800,"objectID":"3ad219e94c230691fe89f6d53e918756","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2017tct/","publishdate":"2017-09-08T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2017tct/","section":"talk","summary":"Spotlight on Interpreting Evidence: The P-value and Beyond 2:45 PM - 3:30 PM Moderators: Eugene H. Blackstone, Stuart J. Pocock\nDiscussants: Donald Cutlip, A. Michael Lincoff, Thomas C. McAndrew, Jan G. P. Tijssen, Marco Valgimigli, Roseann M White\n2:45 PM Proper and Improper Interpretations of the P-value Eugene H. Blackstone\n2:55 PM Beyond Time-to-First Event: Counting Multiple Events, Hierarchical Measures, and Weighted Composites Jan G. P. Tijssen\n3:05 PM Alternatives to Traditional P-value Testing: Bayesian Designs Roseann M White","tags":null,"title":"Spotlight on interpreting evidence: The p-value and beyond (discussant)","type":"talk"},{"authors":null,"categories":null,"content":"","date":1473292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473292800,"objectID":"2e4224c21c454a71efef7a74294573b7","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2016clinicaltrialdesign/","publishdate":"2016-09-08T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2016clinicaltrialdesign/","section":"talk","summary":"","tags":null,"title":"Clinical trial design, Statistics, and Interpretations (discussant)","type":"talk"},{"authors":null,"categories":null,"content":"Fundamentals of Calculus II is the second course in our two-course applied calculus sequence. Fundamentals of Calculus II is a continuation of the study of the calculus of functions of one variable as well as a study of multivariable calculus. This will include area between curves, integration by parts, basic differential equations, separation of variables, solving first-order linear differential equations, Taylor Polynomials and Tayler Series, improper integrals, continuous random variables and probability, functions of several variables, partial derivatives, maxima and minima of multivariable functions, Lagrange multipliers, and double integrals. This basically covers chapters 6 – 11 of the textbook given below. Topics will be presented with a level of depth and rigor appropriate for students pursuing degrees in business, economics, social and life sciences. Please speak to the Department of Mathematics and Statistics if you are unsure if you are taking the correct calculus course.\n","date":1472083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472083200,"objectID":"914043661875b8543029f660cb50f360","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/teaching/2016math020/","publishdate":"2016-08-25T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/teaching/2016math020/","section":"teaching","summary":"Fundamentals of Calculus II is the second course in our two-course applied calculus sequence. Fundamentals of Calculus II is a continuation of the study of the calculus of functions of one variable as well as a study of multivariable calculus. This will include area between curves, integration by parts, basic differential equations, separation of variables, solving first-order linear differential equations, Taylor Polynomials and Tayler Series, improper integrals, continuous random variables and probability, functions of several variables, partial derivatives, maxima and minima of multivariable functions, Lagrange multipliers, and double integrals.","tags":null,"title":"Math020 Fundementals of Calculus II (UVM)","type":"teaching"},{"authors":null,"categories":null,"content":"Cyber-physical systems are critical infrastructures that are crucial both to the reliable delivery of resources such as energy, and to the stable functioning of automatic and control architectures. These systems are composed of interdependent physical, control and communications networks described by disparate mathematical models creating scientific challenges that go well beyond the modeling and analysis of the individual networks. A key challenge in cyber-physical defense is a fast online detection and localization of faults and intrusions without prior knowledge of the failure type. We describe a set of techniques for the efficient identification of faults from correlations in physical signals, assuming only a minimal amount of available system information. The performance of our detection method is illustrated on data collected from a large building automation system.\n","date":1471824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471824000,"objectID":"632a6f89907081d406219c756707b418","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2016cnls/","publishdate":"2016-08-22T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2016cnls/","section":"talk","summary":"Cyber-physical systems are critical infrastructures that are crucial both to the reliable delivery of resources such as energy, and to the stable functioning of automatic and control architectures. These systems are composed of interdependent physical, control and communications networks described by disparate mathematical models creating scientific challenges that go well beyond the modeling and analysis of the individual networks. A key challenge in cyber-physical defense is a fast online detection and localization of faults and intrusions without prior knowledge of the failure type.","tags":null,"title":"Anomaly detection from physical correlations (talk)","type":"talk"},{"authors":null,"categories":null,"content":"Identifying and communicating relationships between causes and effects is important for understanding our world, but is affected by language structure, cognitive and emotional biases, and the properties of the communication medium. Despite the increasing importance of social media, much remains unknown about causal statements made online. To study real-world causal attribution, we extract a large-scale corpus of causal statements made on the Twitter social network platform as well as a comparable random control corpus. We compare causal and control statements using statistical language and sentiment analysis tools. We find that causal statements have a number of significant lexical and grammatical differences compared with controls and tend to be more negative in sentiment than controls. Causal statements made online tend to focus on news and current events, medicine and health, or interpersonal relationships, as shown by topic models. By quantifying the features and potential biases of causality communication, this study improves our understanding of the accuracy of information and opinions found online.\nKeywords social media; online social network; causal attribution; natural language processing\n","date":1471824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471824000,"objectID":"ed87702789602c901f9c445b15d7ce97","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2016whatwe/","publishdate":"2016-08-22T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2016whatwe/","section":"talk","summary":"Identifying and communicating relationships between causes and effects is important for understanding our world, but is affected by language structure, cognitive and emotional biases, and the properties of the communication medium. Despite the increasing importance of social media, much remains unknown about causal statements made online. To study real-world causal attribution, we extract a large-scale corpus of causal statements made on the Twitter social network platform as well as a comparable random control corpus.","tags":null,"title":"What we write about when we write about causality","type":"talk"},{"authors":null,"categories":null,"content":"","date":1430179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430179200,"objectID":"49363eb51129cf6a89ccfa9b60bdeb82","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2015percolation/","publishdate":"2015-04-28T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2015percolation/","section":"talk","summary":"","tags":null,"title":"Percolation on Spatial Networks","type":"talk"},{"authors":null,"categories":null,"content":"","date":1428105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1428105600,"objectID":"ed515b2409d8be31b09e49cd0910a628","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2015ooblex/","publishdate":"2015-04-04T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2015ooblex/","section":"talk","summary":"","tags":null,"title":"Ooblexity: Demonstration of non-newtonian fluids","type":"talk"},{"authors":null,"categories":null,"content":"","date":1427241600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427241600,"objectID":"60a582b94c1495f0e1c485ded199225c","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2015complenet/","publishdate":"2015-03-25T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2015complenet/","section":"talk","summary":"","tags":null,"title":"Robustess of Spatial Micronetworks","type":"talk"},{"authors":null,"categories":null,"content":"","date":1404345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1404345600,"objectID":"70625c8211b9274191cdf26ae92c480b","permalink":"https://thomasmcandrew.com/classes/2019_stat340_MHC/public/talk/2014sfinetwork/","publishdate":"2014-07-03T00:00:00Z","relpermalink":"/classes/2019_stat340_MHC/public/talk/2014sfinetwork/","section":"talk","summary":"","tags":null,"title":"Structural and Functional Robustness in Networks","type":"talk"}]